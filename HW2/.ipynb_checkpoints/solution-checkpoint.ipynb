{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n",
      "lambda = 0;\ttrain=0.732843137255; validate=0.720759338641; test=0.77709736681\n",
      "lambda = 0.01;\ttrain=0.732230392157; validate=0.721984078383; test=0.780159216167\n",
      "lambda = 1.0;\ttrain=0.726715686275; validate=0.704225352113; test=0.766074709124\n",
      "lambda = 100.0;\ttrain=0.658700980392; validate=0.630128597673; test=0.696876913656\n",
      "Best lambda on validation set = 100.0\n",
      "train/valid/test accuracy = (0.7322303921568627, 0.72198407838334355, 0.78015921616656458)\n",
      "Randomized split accuracy\n",
      "lambda = 0;\ttrain=0.742034313725; validate=0.752602571953; test=0.736068585426\n",
      "lambda = 0.01;\ttrain=0.742647058824; validate=0.75566442131; test=0.736068585426\n",
      "lambda = 1.0;\ttrain=0.729166666667; validate=0.739742804654; test=0.728107777097\n",
      "lambda = 100.0;\ttrain=0.655024509804; validate=0.662584200857; test=0.6680955297\n",
      "('TP = ', 1129.0)\n",
      "('TN = ', 145.0)\n",
      "('FP = ', 321.0)\n",
      "('FN = ', 38.0)\n",
      "('BER = ', 0.3607016634119252)\n",
      "Precision@10 = 1.0, Recall@10 = 0.00856898029135\n",
      "Precision@500 = 0.956, Recall@500 = 0.409597257926\n",
      "Precision@1000 = 0.864, Recall@1000 = 0.740359897172\n",
      "[[ -3.23636346e-04   1.42201752e-04   3.17030713e-04   5.36390435e-02\n",
      "    9.30284526e-05   2.54030965e-01   9.65655009e-01   3.19990241e-05\n",
      "   -2.95831396e-04   3.84043646e-04  -1.00526693e-02]\n",
      " [ -7.57985623e-03  -1.66366340e-03   1.04742899e-03   5.21677266e-02\n",
      "    4.49425600e-05   9.65020304e-01  -2.56793964e-01   7.90089050e-06\n",
      "    5.24900596e-04  -1.09699394e-03  -2.89827657e-03]\n",
      " [  1.82124420e-02   2.54680710e-03   3.31838657e-03   9.93221259e-01\n",
      "   -1.51888372e-04  -6.42297821e-02  -3.91682592e-02   4.30929482e-04\n",
      "   -6.93199060e-03  -2.85216045e-03  -8.62920933e-02]\n",
      " [  1.56811999e-01   3.28220652e-03   1.66866136e-02   8.28549640e-02\n",
      "   -6.91822288e-03   1.13029682e-03   5.39110108e-03  -9.49080503e-04\n",
      "    2.68027305e-03   1.30498102e-03   9.83955205e-01]\n",
      " [  9.81360642e-01  -1.45890108e-02   5.92643662e-02  -3.17546064e-02\n",
      "    5.07483182e-04   8.43759364e-03  -1.77578042e-03   6.03725221e-04\n",
      "   -9.05011239e-02  -9.35630845e-03  -1.54417839e-01]\n",
      " [  7.76578401e-02  -2.37665885e-01   2.23406619e-02   5.04113878e-03\n",
      "   -1.43564098e-02  -2.14210997e-04  -2.22913844e-04   3.36617054e-03\n",
      "    8.77254205e-01   4.08570175e-01  -1.54145486e-02]\n",
      " [ -7.36289612e-02  -2.61563804e-01   9.43067566e-01  -2.14514264e-03\n",
      "    1.19104298e-02  -1.68808905e-03   1.42294158e-04  -1.17203197e-04\n",
      "   -1.45895558e-01   1.23868963e-01  -2.88797236e-03]\n",
      " [ -1.37617196e-02   2.11129619e-01  -1.16514121e-01   5.30670319e-04\n",
      "    1.05181628e-02   1.36446528e-03  -8.21179429e-04   3.09221855e-04\n",
      "   -3.58358431e-01   9.01728510e-01   3.27758247e-03]\n",
      " [  1.74575775e-02   9.10890084e-01   3.04081497e-01  -2.89763923e-03\n",
      "    2.34615054e-02   1.17406025e-03  -3.85957239e-04   1.23176271e-03\n",
      "    2.68927937e-01  -6.70756658e-02  -1.12101920e-02]\n",
      " [  2.31513441e-03  -2.38717789e-02  -1.67445603e-02   8.92206499e-04\n",
      "    9.99462734e-01  -9.81109101e-05  -3.32812875e-05   4.14235255e-03\n",
      "    1.18483756e-02  -3.51543098e-03   6.92344110e-03]\n",
      " [  7.48312160e-04   3.08204153e-04   2.55232500e-04   3.49846801e-04\n",
      "    4.12943179e-03  -6.96565372e-06   4.16951216e-06  -9.99984215e-01\n",
      "    3.17948604e-03   1.53436134e-03  -1.10029138e-03]]\n",
      "Reconstruction error when replacing points by the mean of the corresponding coordinate:\n",
      "3675818.61688\n",
      "First transformed data point [[  1.76611818e+02   7.73266745e-01   1.03590798e+01   1.24531982e+01\n",
      "    4.67344579e+00   3.22698912e+00  -7.49640232e-01  -7.88158703e-01\n",
      "    1.08509039e+00   1.56140166e-01  -9.87201543e-01]]\n",
      "Reconstruction error in the new basis:\n",
      "1345.4755741\n",
      "Using 1 dimensions, MSE (train/test) = 0.863842439736/0.663483489967\n",
      "Using 2 dimensions, MSE (train/test) = 0.844669431856/0.655587493167\n",
      "Using 3 dimensions, MSE (train/test) = 0.827516115585/0.678359151931\n",
      "Using 4 dimensions, MSE (train/test) = 0.697383278875/0.599090621981\n",
      "Using 5 dimensions, MSE (train/test) = 0.685501559879/0.623198156483\n",
      "Using 6 dimensions, MSE (train/test) = 0.660853988987/0.603878380071\n",
      "Using 7 dimensions, MSE (train/test) = 0.659194511545/0.597279959249\n",
      "Using 8 dimensions, MSE (train/test) = 0.65848602461/0.594506224412\n",
      "Using 9 dimensions, MSE (train/test) = 0.636856614278/0.555505096146\n",
      "Using 10 dimensions, MSE (train/test) = 0.634687819148/0.556201920206\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from math import exp\n",
    "from math import log\n",
    "from sklearn.decomposition import PCA\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "def parseData(fname):\n",
    "  for l in urllib.urlopen(fname):\n",
    "    yield eval(l)\n",
    "\n",
    "print(\"Reading data...\")\n",
    "dataFile = open(\"winequality-white.csv\")\n",
    "header = dataFile.readline()\n",
    "fields = [\"constant\"] + header.strip().replace('\"','').split(';')\n",
    "featureNames = fields[:-1]\n",
    "labelName = fields[-1]\n",
    "lines = [[1.0] + [float(x) for x in l.split(';')] for l in dataFile]\n",
    "X = [l[:-1] for l in lines]\n",
    "y = [l[-1] > 5 for l in lines]\n",
    "y_rating = [l[-1] for l in lines]\n",
    "print(\"done\")\n",
    "\n",
    "def inner(x,y):\n",
    "  return sum([x[i]*y[i] for i in range(len(x))])\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1.0 / (1 + exp(-x))\n",
    "\n",
    "##################################################\n",
    "# Logistic regression by gradient ascent         #\n",
    "##################################################\n",
    "\n",
    "# NEGATIVE Log-likelihood\n",
    "def f(theta, X, y, lam):\n",
    "  loglikelihood = 0\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    loglikelihood -= log(1 + exp(-logit))\n",
    "    if not y[i]:\n",
    "      loglikelihood -= logit\n",
    "  for k in range(len(theta)):\n",
    "    loglikelihood -= lam * theta[k]*theta[k]\n",
    "  # for debugging\n",
    "  # print \"ll =\", loglikelihood\n",
    "  return -loglikelihood\n",
    "\n",
    "# NEGATIVE Derivative of log-likelihood\n",
    "def fprime(theta, X, y, lam):\n",
    "  dl = [0]*len(theta)\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    for k in range(len(theta)):\n",
    "      dl[k] += X[i][k] * (1 - sigmoid(logit))\n",
    "      if not y[i]:\n",
    "        dl[k] -= X[i][k]\n",
    "  for k in range(len(theta)):\n",
    "    dl[k] -= lam*2*theta[k]\n",
    "  return numpy.array([-x for x in dl])\n",
    "\n",
    "X_train = X[:int(len(X)/3)]\n",
    "y_train = y[:int(len(y)/3)]\n",
    "X_validate = X[int(len(X)/3):int(2*len(X)/3)]\n",
    "y_validate = y[int(len(y)/3):int(2*len(y)/3)]\n",
    "X_test = X[int(2*len(X)/3):]\n",
    "y_test = y[int(2*len(X)/3):]\n",
    "\n",
    "##################################################\n",
    "# Train                                          #\n",
    "##################################################\n",
    "\n",
    "def train(lam):\n",
    "  theta,_,_ = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(X[0]), fprime, pgtol = 10, args = (X_train, y_train, lam))\n",
    "  return theta\n",
    "\n",
    "##################################################\n",
    "# Predict                                        #\n",
    "##################################################\n",
    "\n",
    "def performance(theta, y_train, y_validate, y_test, X_train, X_validate, X_test):\n",
    "  scores_train = [inner(theta,x) for x in X_train]\n",
    "  scores_validate = [inner(theta,x) for x in X_validate]\n",
    "  scores_test = [inner(theta,x) for x in X_test]\n",
    "  predictions_train = [s > 0 for s in scores_train]\n",
    "  predictions_validate = [s > 0 for s in scores_validate]\n",
    "  predictions_test = [s > 0 for s in scores_test]\n",
    "  correct_train = [(a==b) for (a,b) in zip(predictions_train,y_train)]\n",
    "  correct_validate = [(a==b) for (a,b) in zip(predictions_validate,y_validate)]\n",
    "  correct_test = [(a==b) for (a,b) in zip(predictions_test,y_test)]\n",
    "  acc_train = sum(correct_train) * 1.0 / len(correct_train)\n",
    "  acc_validate = sum(correct_validate) * 1.0 / len(correct_validate)\n",
    "  acc_test = sum(correct_test) * 1.0 / len(correct_test)\n",
    "  TP = float(sum([(a and b) for (a,b) in zip(predictions_test, y_test)]))\n",
    "  TN = float(sum([(not a and not b) for (a,b) in zip(predictions_test, y_test)]))\n",
    "  FP = float(sum([(a and not b) for (a,b) in zip(predictions_test, y_test)]))\n",
    "  FN = float(sum([(not a and b) for (a,b) in zip(predictions_test, y_test)]))\n",
    "  TPR = TP / (TP + FN)\n",
    "  TNR = TN / (TN + FP)\n",
    "  BER = 1.0 - 0.5*(TPR + TNR)\n",
    "  labelsSortedByScore = list(zip(scores_test, y_test))\n",
    "  labelsSortedByScore.sort()\n",
    "  labelsSortedByScore.reverse()\n",
    "  labelsSortedByScore = [a[1] for a in labelsSortedByScore]\n",
    "  return acc_train, acc_validate, acc_test, (TP, TN, FP, FN, BER), labelsSortedByScore\n",
    "\n",
    "##################################################\n",
    "# Validation pipeline                            #\n",
    "##################################################\n",
    "\n",
    "bestLambda = None\n",
    "bestLambdaAcc = None\n",
    "bestValidate = None\n",
    "\n",
    "for lam in [0, 0.01, 1.0, 100.0]:\n",
    "  theta = train(lam)\n",
    "  acc_train, acc_validate, acc_test, _, _ = performance(theta, y_train, y_validate, y_test, X_train, X_validate, X_test)\n",
    "  if (not bestLambda) or acc_validate > bestValidate:\n",
    "    bestLambda = lam\n",
    "    bestValidate = acc_validate\n",
    "    bestLambdaAcc = (acc_train, acc_validate, acc_test)\n",
    "  print(\"lambda = \" + str(lam) + \";\\ttrain=\" + str(acc_train) + \"; validate=\" + str(acc_validate) + \"; test=\" + str(acc_test))\n",
    "\n",
    "print(\"Best lambda on validation set = \" + str(lam))\n",
    "print(\"train/valid/test accuracy = \" + str(bestLambdaAcc))\n",
    "\n",
    "##################################################\n",
    "# Randomly reshuffle the data                    #\n",
    "##################################################\n",
    "\n",
    "Xy = list(zip(X, y))\n",
    "random.shuffle(Xy)\n",
    "X_rand = [a[0] for a in Xy]\n",
    "y_rand = [a[1] for a in Xy]\n",
    "\n",
    "X_train_rand = X_rand[:int(len(X_rand)/3)]\n",
    "y_train_rand = y_rand[:int(len(y_rand)/3)]\n",
    "X_validate_rand = X_rand[int(len(X_rand)/3):int(2*len(X_rand)/3)]\n",
    "y_validate_rand = y_rand[int(len(y_rand)/3):int(2*len(y_rand)/3)]\n",
    "X_test_rand = X_rand[int(2*len(X_rand)/3):]\n",
    "y_test_rand = y_rand[int(2*len(X_rand)/3):]\n",
    "\n",
    "print(\"Randomized split accuracy\")\n",
    "for lam in [0, 0.01, 1.0, 100.0]:\n",
    "  theta = train(lam)\n",
    "  acc_train, acc_validate, acc_test, _, _ = performance(theta, y_train_rand, y_validate_rand, y_test_rand, X_train_rand, X_validate_rand, X_test_rand)\n",
    "  print(\"lambda = \" + str(lam) + \";\\ttrain=\" + str(acc_train) + \"; validate=\" + str(acc_validate) + \"; test=\" + str(acc_test))\n",
    "\n",
    "##################################################\n",
    "# Error rates                                    #\n",
    "##################################################\n",
    "theta = train(0.01)\n",
    "\n",
    "_, _, _, (TP, TN, FP, FN, BER), labelsSortedByScore = performance(theta, y_train, y_validate, y_test, X_train, X_validate, X_test)\n",
    "\n",
    "print(\"TP = \", TP)\n",
    "print(\"TN = \", TN)\n",
    "print(\"FP = \", FP)\n",
    "print(\"FN = \", FN)\n",
    "print(\"BER = \", BER)\n",
    "\n",
    "##################################################\n",
    "# Precision @ k                                  #\n",
    "##################################################\n",
    "\n",
    "for k in 10, 500, 1000:\n",
    "  nReturnedDocs = k\n",
    "  nRelevantDocs = sum(labelsSortedByScore)\n",
    "  nRelevantReturnedDocs = sum(labelsSortedByScore[:k])\n",
    "  precisionK = nRelevantReturnedDocs * 1.0 / nReturnedDocs\n",
    "  recallK = nRelevantReturnedDocs * 1.0 / nRelevantDocs\n",
    "  print(\"Precision@\" + str(k) + \" = \" + str(precisionK) + \", Recall@\" + str(k) + \" = \" + str(recallK))\n",
    "\n",
    "##################################################\n",
    "# Precision/Recall curve                         #\n",
    "##################################################\n",
    "\n",
    "precision = []\n",
    "recall = []\n",
    "\n",
    "relevantDocsReturned = 0\n",
    "\n",
    "for i in range(len(labelsSortedByScore)):\n",
    "  if labelsSortedByScore[i]:\n",
    "    relevantDocsReturned += 1\n",
    "  precision.append(relevantDocsReturned / (i+1))\n",
    "  recall.append(relevantDocsReturned / len(labelsSortedByScore))\n",
    "\n",
    "# plt.plot(recall, precision)\n",
    "# plt.show()\n",
    "\n",
    "##################################################\n",
    "# PCA                                            #\n",
    "##################################################\n",
    "\n",
    "Xn = [x[1:] for x in X_train] # Drop the offset (shouldn't make a significant difference to answers)\n",
    "Xn = numpy.matrix(Xn)\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(Xn)\n",
    "\n",
    "print(pca.components_)\n",
    "\n",
    "##################################################\n",
    "# Replace points by their mean                   #\n",
    "##################################################\n",
    "\n",
    "print(\"Reconstruction error when replacing points by the mean of the corresponding coordinate:\")\n",
    "print(numpy.linalg.norm(Xn - Xn.mean(0))**2) \n",
    "\n",
    "##################################################\n",
    "# Reconstruction error with four dimensions      #\n",
    "##################################################\n",
    "\n",
    "Yn = Xn*pca.components_.T\n",
    "\n",
    "print(\"First transformed data point \" + str(Yn[0]))\n",
    "\n",
    "yVar = numpy.var(Yn,0)\n",
    "print(\"Reconstruction error in the new basis:\")\n",
    "print(len(Yn) * sum(yVar.tolist()[0][4:])) # Reconstruction error\n",
    "\n",
    "##################################################\n",
    "# Using the features with a regressor            #\n",
    "##################################################\n",
    "\n",
    "Xn_test = [x[1:] for x in X_test]\n",
    "Xn_test = numpy.matrix(Xn_test)\n",
    "Yn_test = Xn_test*pca.components_.T\n",
    "\n",
    "y_train = y_rating[:int(len(y)/3)]\n",
    "y_test = y_rating[int(2*len(X)/3):]\n",
    "\n",
    "for i in range(1, len(pca.components_)):\n",
    "  Xnew_train = [[1] + x[:i] for x in Yn.tolist()]\n",
    "  Xnew_test = [[1] + x[:i] for x in Yn_test.tolist()]\n",
    "  theta,residuals,rank,s = numpy.linalg.lstsq(Xnew_train, y_train)\n",
    "  MSE_train = residuals[0] / len(Xnew_train)\n",
    "  predictions_test = [inner(x,theta) for x in Xnew_test]\n",
    "  MSE_test = [(a-b)**2 for (a,b) in zip(predictions_test, y_test)]\n",
    "  MSE_test = sum(MSE_test) / len(MSE_test)\n",
    "  print(\"Using \" + str(i) + \" dimensions, MSE (train/test) = \" + str(MSE_train) + '/' + str(MSE_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[  7.02365196e+00,   2.80015319e-01,   3.65263480e-01,\n",
       "           6.03155637e+00,   4.64485294e-02,   3.48511029e+01,\n",
       "           1.43578125e+02,   9.94381281e-01,   3.20603554e+00,\n",
       "           4.86072304e-01,   1.02900735e+01]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xn.mean(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
