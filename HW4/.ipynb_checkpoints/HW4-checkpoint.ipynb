{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import string\n",
    "from sklearn import linear_model\n",
    "import math\n",
    "\n",
    "def parseData(fname):\n",
    "  for l in open(fname):\n",
    "    yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "### Just the first 5000 reviews\n",
    "\n",
    "print \"Reading data...\"\n",
    "data = list(parseData(\"beer_50000.json\"))[:5000]\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182246 unique bigrams\n"
     ]
    }
   ],
   "source": [
    "### Ignore capitalization and remove punctuation\n",
    "unigram_count = defaultdict(int)\n",
    "bigram_count = defaultdict(int)\n",
    "hybrid_count = defaultdict(int)\n",
    "\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data:\n",
    "    r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    words = r.split()\n",
    "    for w1, w2 in zip(words[:-1], words[1:]):\n",
    "        unigram_count[w1] += 1\n",
    "        bigram_count[w1 + ' ' + w2] += 1\n",
    "    if len(words) > 0:\n",
    "        unigram_count[words[-1]] += 1\n",
    "\n",
    "hybrid_count.update(unigram_count)\n",
    "hybrid_count.update(bigram_count)\n",
    "\n",
    "# print len(unigram_count), \"unique unigrams\"\n",
    "print len(bigram_count), \"unique bigrams\"\n",
    "# print len(hybrid_count), \"unique hybrids\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular bigrams\n",
      "with a: 4587, in the: 2595, of the: 2245, is a: 2056, on the: 2033\n"
     ]
    }
   ],
   "source": [
    "### Just take the most popular words...\n",
    "\n",
    "bigram_counts = [(bigram_count[w], w) for w in bigram_count]\n",
    "bigram_counts.sort()\n",
    "bigram_counts.reverse()\n",
    "bigrams = [x[1] for x in bigram_counts[:1000]]\n",
    "\n",
    "print \"Most popular bigrams\"\n",
    "print ', '.join([bigram + ': ' + str(count) for count, bigram in bigram_counts[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.343153014061\n"
     ]
    }
   ],
   "source": [
    "### Sentiment analysis\n",
    "\n",
    "bigramId = dict(zip(bigrams, range(len(bigrams))))\n",
    "bigramSet = set(bigrams)\n",
    "\n",
    "def feature_bigrams(datum):\n",
    "    feat = [0]*len(bigrams)\n",
    "    r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    for w1, w2 in zip(r.split()[:-1], r.split()[1:]):\n",
    "        if (w1 + ' ' + w2) in bigrams:\n",
    "            feat[bigramId[w1 + ' ' + w2]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [feature_bigrams(d) for d in data]\n",
    "y = [d['review/overall'] for d in data]\n",
    "\n",
    "#No regularization\n",
    "#theta,residuals,rank,s = numpy.linalg.lstsq(X, y)\n",
    "\n",
    "#With regularization\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)\n",
    "print numpy.dot(predictions - y, predictions - y) / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular unigrams + bigrams\n",
      "[(30695, 'a'), (27569, 'the'), (19512, 'and'), (15935, 'of'), (12623, 'is')]\n"
     ]
    }
   ],
   "source": [
    "hybrid_counts = [(hybrid_count[w], w) for w in hybrid_count]\n",
    "hybrid_counts.sort()\n",
    "hybrid_counts.reverse()\n",
    "hybrids = [x[1] for x in hybrid_counts[:1000]]\n",
    "\n",
    "print \"Most popular unigrams + bigrams\"\n",
    "print hybrid_counts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.289953747306\n"
     ]
    }
   ],
   "source": [
    "hybridId = dict(zip(hybrids, range(len(hybrids))))\n",
    "hybridSet = set(hybrids)\n",
    "\n",
    "def feature_hybrids(datum):\n",
    "    feat = [0]*len(hybrids)\n",
    "    r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    for w1, w2 in zip(r.split()[:-1], r.split()[1:]):\n",
    "        if w1 in hybrids:\n",
    "            feat[hybridId[w1]] += 1\n",
    "        if w2 in hybrids:\n",
    "            feat[hybridId[w2]] += 1\n",
    "        if (w1 + ' ' + w2) in hybrids:\n",
    "            feat[hybridId[w1 + ' ' + w2]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [feature_hybrids(d) for d in data]\n",
    "y = [d['review/overall'] for d in data]\n",
    "\n",
    "#With regularization\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)\n",
    "print numpy.dot(predictions - y, predictions - y) / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(-0.69265745727633066, 'sort of'),\n",
       "  (-0.22848928122639411, 'the background'),\n",
       "  (-0.17568277356502954, 'around the'),\n",
       "  (-0.16972494240234998, 'down the'),\n",
       "  (-0.14204940691157014, 'i will')],\n",
       " [(0.20527676503518508, 'the best'),\n",
       "  (0.20745459134343039, 'not bad'),\n",
       "  (0.21912455033569869, 'of these'),\n",
       "  (0.23171208948268693, 'a bad'),\n",
       "  (0.28954668154631069, 'sort')])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments = sorted(zip(theta[:-1], hybrids))\n",
    "sentiments[:5], sentiments[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word\t\tIDF\t\tTF-IDF\n",
      "foam \t1.10902040301 \t2.21804080602\n",
      "smell \t0.450751443146 \t0.450751443146\n",
      "banana \t1.51999305704 \t3.03998611409\n",
      "lactic \t2.7447274949 \t5.48945498979\n",
      "tart \t1.71219827007 \t1.71219827007\n"
     ]
    }
   ],
   "source": [
    "words = [\"foam\", \"smell\", \"banana\", \"lactic\", \"tart\"]\n",
    "\n",
    "def remove_punct(review):\n",
    "    return ''.join([c for c in review['review/text'].lower() if not c in string.punctuation]).split()\n",
    "\n",
    "def idf(word):\n",
    "    return math.log10(float(len(data)) / unigram_count[word]) if unigram_count[word] > 0 else 0\n",
    "\n",
    "def tf_idf(word, review):\n",
    "    freq = sum([1 for w in remove_punct(review) if w == word])\n",
    "    return freq * idf(word)\n",
    "\n",
    "print \"Word\\t\\tIDF\\t\\tTF-IDF\"\n",
    "for word in words:\n",
    "    print word, '\\t', idf(word), '\\t', tf_idf(word, data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unigram_counts = [(unigram_count[w], w) for w in unigram_count]\n",
    "unigram_counts.sort()\n",
    "unigram_counts.reverse()\n",
    "unigrams = [x[1] for x in unigram_counts[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First/second review cosine similarity 0.400835532702\n"
     ]
    }
   ],
   "source": [
    "tf_idf_0 = map(lambda word: tf_idf(word, data[0]), unigrams)\n",
    "tf_idf_1 = map(lambda word: tf_idf(word, data[1]), unigrams)\n",
    "print \"First/second review cosine similarity\", numpy.dot(tf_idf_0, tf_idf_1) / (numpy.linalg.norm(tf_idf_0) * numpy.linalg.norm(tf_idf_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 reviews processed\n",
      "1000 reviews processed\n",
      "2000 reviews processed\n",
      "3000 reviews processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python2.7/site-packages/ipykernel/__main__.py:9: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 reviews processed\n",
      "{'beer/style': 'Hefeweizen', 'beer/ABV': 6.0, 'beer/beerId': '36862', 'review/timeStruct': {'wday': 6, 'isdst': 0, 'mday': 24, 'hour': 18, 'min': 55, 'sec': 54, 'year': 2008, 'yday': 55, 'mon': 2}, 'review/aroma': 3.5, 'review/appearance': 3.5, 'review/timeUnix': 1203879354, 'review/palate': 2.5, 'review/taste': 3.0, 'beer/name': 'Wild Frog Wheat Ale', 'beer/brewerId': '14879', 'review/overall': 2.5, 'review/text': \"22 oz. bomber bottle that has the same picture as every other Hoppin' Frog label, a happy smiling hopping frog toasting a pint of beer. Since this is a wheat ale, all the mugs of beer on the label have a yellow colored liquid inside them. Not only does this label have all the usual stuff (Government warning, address, barcode, etc), but it also has a wealth of information. On the right side it has a nice sized paragraph talking about the style and the beer itself and just below that it is where they list the beer's specifications of 6.0% ABV, 58 OG, 14 FG, and 12 IBU. Don't waste your time looking for any kind of date because Hoppin Frog doesn't date their bottles. \\t\\tAppearance: When poured into a Weizen glass, this Wild Frog was a hazy straw color that was mixed in a dash of lemon yellow coloring. It had the usual Hefeweizen tall head of white foam to it. Like every other Hefeweizen, when it receded it left behind a small white film and streaks of white lace around the glass.\\t\\tSmell: It had a nice ripe banana aroma to it. That ripe banana stuck out as the main aroma of this beer. There's was only a few other aromas behind that and that was a dash of pepper, a few cloves, a pinch of malted wheat, and a touch of citrus fruits and hops. Basically it had a standard Hefeweizen aroma to it, but that ripe banana really stood out.\\t\\tTaste: I just couldn't get excited over the taste of this beer. There wasn't much to it. The taste was one big mixture of malted wheat, banana, yeast, lemon zest, orange spice, and lightly bitter citrus hops. Not one flavor stood out as being more than average. The taste was stnadard and average at best.\\t\\tMouthfeel: It was crispy and light like the Hefeweizen style is suppose to be, but I thought the aftertaste was far too light. The aftertaste was that of malted wheat, citrus hops, and a small touch of banana.\\t\\tDrinkability: I can't say alot about this beer because there wasn't alot to this beer. I've said this before and I'm going to say it again, it's just a standard American Hefeweizen. There are better and shall I say cheaper alternatives to this one. One is more than enough for me.\", 'user/profileName': 'AltBock'} 0.546596320621\n"
     ]
    }
   ],
   "source": [
    "tf_idf_0 = map(lambda word: tf_idf(word, data[0]), unigrams)\n",
    "closest_review = None\n",
    "closest_similarity = -1\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for d in data[1:]:\n",
    "    tf_idf_curr = map(lambda word: tf_idf(word, d), unigrams)\n",
    "    similarity = numpy.dot(tf_idf_curr, tf_idf_0) / (numpy.linalg.norm(tf_idf_curr) * numpy.linalg.norm(tf_idf_0))\n",
    "    if similarity > closest_similarity:\n",
    "        closest_review = d\n",
    "        closest_similarity = similarity\n",
    "    if counter % 1000 == 0:\n",
    "        print counter, \"reviews processed\"\n",
    "    counter += 1\n",
    "print closest_review, closest_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 reviews processed\n",
      "200 reviews processed\n",
      "400 reviews processed\n",
      "600 reviews processed\n",
      "800 reviews processed\n",
      "1000 reviews processed\n",
      "1200 reviews processed\n",
      "1400 reviews processed\n",
      "1600 reviews processed\n",
      "1800 reviews processed\n",
      "2000 reviews processed\n",
      "2200 reviews processed\n",
      "2400 reviews processed\n",
      "2600 reviews processed\n",
      "2800 reviews processed\n",
      "3000 reviews processed\n",
      "3200 reviews processed\n",
      "3400 reviews processed\n",
      "3600 reviews processed\n",
      "3800 reviews processed\n",
      "4000 reviews processed\n",
      "4200 reviews processed\n",
      "4400 reviews processed\n",
      "4600 reviews processed\n",
      "4800 reviews processed\n"
     ]
    }
   ],
   "source": [
    "# tf_idf_X = [[map(lambda word: tf_idf(word, d), unigrams) for word in unigrams] + [1] for d in data]\n",
    "\n",
    "tf_idf_X = []\n",
    "counter = 0\n",
    "\n",
    "for d in data:\n",
    "    tf_idf_X.append(map(lambda word: tf_idf(word, d), unigrams) + [1])\n",
    "    if counter % 200 == 0:\n",
    "        print counter, \"reviews processed\"\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_idf_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.279053464267\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(tf_idf_X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(tf_idf_X)\n",
    "print numpy.dot(predictions - y, predictions - y) / len(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
