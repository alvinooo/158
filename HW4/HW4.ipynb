{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import string\n",
    "from sklearn import linear_model\n",
    "import math\n",
    "\n",
    "def parseData(fname):\n",
    "  for l in open(fname):\n",
    "    yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "### Just the first 5000 reviews\n",
    "\n",
    "print \"Reading data...\"\n",
    "data = list(parseData(\"beer_50000.json\"))[:5000]\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182246 unique bigrams\n"
     ]
    }
   ],
   "source": [
    "### Ignore capitalization and remove punctuation\n",
    "unigram_count = defaultdict(int)\n",
    "bigram_count = defaultdict(int)\n",
    "hybrid_count = defaultdict(int)\n",
    "\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data:\n",
    "    r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    words = r.split()\n",
    "    for w1, w2 in zip(words[:-1], words[1:]):\n",
    "        unigram_count[w1] += 1\n",
    "        bigram_count[w1 + ' ' + w2] += 1\n",
    "    if len(words) > 0:\n",
    "        unigram_count[words[-1]] += 1\n",
    "\n",
    "hybrid_count.update(unigram_count)\n",
    "hybrid_count.update(bigram_count)\n",
    "\n",
    "# print len(unigram_count), \"unique unigrams\"\n",
    "print len(bigram_count), \"unique bigrams\"\n",
    "# print len(hybrid_count), \"unique hybrids\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular bigrams\n",
      "with a: 4587, in the: 2595, of the: 2245, is a: 2056, on the: 2033\n"
     ]
    }
   ],
   "source": [
    "### Just take the most popular words...\n",
    "\n",
    "bigram_counts = [(bigram_count[w], w) for w in bigram_count]\n",
    "bigram_counts.sort()\n",
    "bigram_counts.reverse()\n",
    "bigrams = [x[1] for x in bigram_counts[:1000]]\n",
    "\n",
    "print \"Most popular bigrams\"\n",
    "print ', '.join([bigram + ': ' + str(count) for count, bigram in bigram_counts[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1715.76507031\n"
     ]
    }
   ],
   "source": [
    "### Sentiment analysis\n",
    "\n",
    "bigramId = dict(zip(bigrams, range(len(bigrams))))\n",
    "bigramSet = set(bigrams)\n",
    "\n",
    "def feature_bigrams(datum):\n",
    "    feat = [0]*len(bigrams)\n",
    "    r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    for w1, w2 in zip(r.split()[:-1], r.split()[1:]):\n",
    "        if (w1 + ' ' + w2) in bigrams:\n",
    "            feat[bigramId[w1 + ' ' + w2]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [feature_bigrams(d) for d in data]\n",
    "y = [d['review/overall'] for d in data]\n",
    "\n",
    "#No regularization\n",
    "#theta,residuals,rank,s = numpy.linalg.lstsq(X, y)\n",
    "\n",
    "#With regularization\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)\n",
    "print numpy.dot(predictions - y, predictions - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular unigrams + bigrams\n",
      "[(30695, 'a'), (27569, 'the'), (19512, 'and'), (15935, 'of'), (12623, 'is')]\n"
     ]
    }
   ],
   "source": [
    "hybrid_counts = [(hybrid_count[w], w) for w in hybrid_count]\n",
    "hybrid_counts.sort()\n",
    "hybrid_counts.reverse()\n",
    "hybrids = [x[1] for x in hybrid_counts[:1000]]\n",
    "\n",
    "print \"Most popular unigrams + bigrams\"\n",
    "print hybrid_counts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1449.76873653\n"
     ]
    }
   ],
   "source": [
    "hybridId = dict(zip(hybrids, range(len(hybrids))))\n",
    "hybridSet = set(hybrids)\n",
    "\n",
    "def feature_hybrids(datum):\n",
    "    feat = [0]*len(hybrids)\n",
    "    r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    for w1, w2 in zip(r.split()[:-1], r.split()[1:]):\n",
    "        if w1 in hybrids:\n",
    "            feat[hybridId[w1]] += 1\n",
    "        if w2 in hybrids:\n",
    "            feat[hybridId[w2]] += 1\n",
    "        if (w1 + ' ' + w2) in hybrids:\n",
    "            feat[hybridId[w1 + ' ' + w2]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [feature_hybrids(d) for d in data]\n",
    "y = [d['review/overall'] for d in data]\n",
    "\n",
    "#With regularization\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)\n",
    "print numpy.dot(predictions - y, predictions - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(-0.69265745727633066, 'sort of'),\n",
       "  (-0.22848928122639411, 'the background'),\n",
       "  (-0.17568277356502954, 'around the'),\n",
       "  (-0.16972494240234998, 'down the'),\n",
       "  (-0.14204940691157014, 'i will')],\n",
       " [(0.20527676503518508, 'the best'),\n",
       "  (0.20745459134343039, 'not bad'),\n",
       "  (0.21912455033569869, 'of these'),\n",
       "  (0.23171208948268693, 'a bad'),\n",
       "  (0.28954668154631069, 'sort')])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments = sorted(zip(theta[:-1], hybrids))\n",
    "sentiments[:5], sentiments[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word\t\tIDF\t\tTF-IDF\n",
      "foam \t1.10902040301 \t2.21804080602\n",
      "smell \t0.450751443146 \t0.450751443146\n",
      "banana \t1.51999305704 \t3.03998611409\n",
      "lactic \t2.7447274949 \t5.48945498979\n",
      "tart \t1.71219827007 \t1.71219827007\n"
     ]
    }
   ],
   "source": [
    "words = [\"foam\", \"smell\", \"banana\", \"lactic\", \"tart\"]\n",
    "\n",
    "def remove_punct(review):\n",
    "    return ''.join([c for c in review['review/text'].lower() if not c in string.punctuation]).split()\n",
    "\n",
    "def idf(word):\n",
    "    return math.log10(float(len(data)) / unigram_count[word]) if unigram_count[word] > 0 else 0\n",
    "\n",
    "def tf_idf(word, review):\n",
    "    freq = sum([1 for w in remove_punct(review) if w == word])\n",
    "    return freq * idf(word)\n",
    "\n",
    "print \"Word\\t\\tIDF\\t\\tTF-IDF\"\n",
    "for word in words:\n",
    "    print word, '\\t', idf(word), '\\t', tf_idf(word, data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unigram_counts = [(unigram_count[w], w) for w in unigram_count]\n",
    "unigram_counts.sort()\n",
    "unigram_counts.reverse()\n",
    "unigrams = [x[1] for x in unigram_counts[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First/second review cosine similarity 0.400835532702\n"
     ]
    }
   ],
   "source": [
    "tf_idf_0 = map(lambda word: tf_idf(word, data[0]), unigrams)\n",
    "tf_idf_1 = map(lambda word: tf_idf(word, data[1]), unigrams)\n",
    "print \"First/second review cosine similarity\", numpy.dot(tf_idf_0, tf_idf_1) / (numpy.linalg.norm(tf_idf_0) * numpy.linalg.norm(tf_idf_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 reviews processed\n",
      "{'beer/style': 'Herbed / Spiced Beer', 'beer/ABV': 4.7, 'beer/beerId': '52159', 'review/timeStruct': {'wday': 0, 'isdst': 0, 'mday': 2, 'hour': 17, 'min': 17, 'sec': 39, 'year': 2012, 'yday': 2, 'mon': 1}, 'review/aroma': 3.5, 'review/appearance': 3.5, 'review/timeUnix': 1325524659, 'review/palate': 3.0, 'review/taste': 3.5, 'beer/name': 'Caldera Ginger Beer', 'user/gender': 'Male', 'beer/brewerId': '1075', 'review/overall': 3.0, 'review/text': \"Poured from the bottle into a Chimay goblet.\\t\\tAppearance: Pours a slightly cloudy yellow/orange color with a half finger of fluffy white head. The head fades to a small layer on top of the pour.\\t\\tSmell: Very light and crisp. I'm definitely picking up the ginger, but it's not overly powerful. There is a slight sweetness from the malt as well.\\t\\tTaste: Very light and refreshing. The ginger shows up right away and then fades towards the finish of the sip. The finish is malty and bread like. \\t\\tMouthfeel: The body is on the thin side with smooth carbonation and a very dry finish.\\t\\tOverall: This is a light and refreshing beer, but nothing spectacular. The amount of ginger is nice, but I would have liked to have more going on.\", 'user/profileName': 'oline73'} 0.428283925716\n"
     ]
    }
   ],
   "source": [
    "tf_idf_0 = map(lambda word: tf_idf(word, data[0]), unigrams)\n",
    "closest_review = None\n",
    "closest_similarity = -1\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for d in data[1:]:\n",
    "    tf_idf_curr = map(lambda word: tf_idf(word, d), unigrams)\n",
    "    similarity = numpy.dot(tf_idf_curr, tf_idf_0) / (numpy.linalg.norm(tf_idf_curr) * numpy.linalg.norm(tf_idf_0))\n",
    "    if similarity > closest_similarity:\n",
    "        closest_review = d\n",
    "        closest_similarity = similarity\n",
    "    if counter % 1000 == 0:\n",
    "        print counter, \"reviews processed\"\n",
    "    counter += 1\n",
    "print closest_review, closest_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 reviews processed\n",
      "200 reviews processed\n",
      "400 reviews processed\n",
      "600 reviews processed\n",
      "800 reviews processed\n",
      "1000 reviews processed\n",
      "1200 reviews processed\n",
      "1400 reviews processed\n",
      "1600 reviews processed\n",
      "1800 reviews processed\n",
      "2000 reviews processed\n",
      "2200 reviews processed\n",
      "2400 reviews processed\n",
      "2600 reviews processed\n",
      "2800 reviews processed\n",
      "3000 reviews processed\n",
      "3200 reviews processed\n",
      "3400 reviews processed\n",
      "3600 reviews processed\n",
      "3800 reviews processed\n",
      "4000 reviews processed\n",
      "4200 reviews processed\n",
      "4400 reviews processed\n",
      "4600 reviews processed\n",
      "4800 reviews processed\n"
     ]
    }
   ],
   "source": [
    "# tf_idf_X = [[map(lambda word: tf_idf(word, d), unigrams) for word in unigrams] + [1] for d in data]\n",
    "\n",
    "tf_idf_X = []\n",
    "counter = 0\n",
    "\n",
    "for d in data:\n",
    "    tf_idf_X.append(map(lambda word: tf_idf(word, d), unigrams) + [1])\n",
    "    if counter % 200 == 0:\n",
    "        print counter, \"reviews processed\"\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_idf_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1395.26732133\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(tf_idf_X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(tf_idf_X)\n",
    "print numpy.dot(predictions - y, predictions - y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
