{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import random\n",
    "import numpy as np\n",
    "import string\n",
    "import operator\n",
    "from collections import defaultdict\n",
    "from sklearn import svm\n",
    "\n",
    "def readGz(f):\n",
    "  for l in gzip.open(f):\n",
    "    yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Category prediction\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    feature = [l['reviewerID'], l['reviewText'], l['summary']]\n",
    "    feature.extend([0, l['price']] if 'price' in l else [1, 0])\n",
    "    data.append(feature) # Feature matrix\n",
    "    labels.append(l['categoryID'])\n",
    "\n",
    "pairs = zip(data, labels)\n",
    "random.seed(0)\n",
    "random.shuffle(pairs)\n",
    "data, labels = zip(*pairs)\n",
    "\n",
    "train_data, train_labels = data[:len(data) / 2], labels[:len(labels) / 2]\n",
    "valid_data, valid_labels = data[len(data) / 2:], labels[len(labels) / 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_keywords(data, labels, index):\n",
    "    word_count = defaultdict(int)\n",
    "    word_count_category = defaultdict(lambda : defaultdict(int))\n",
    "    punctuation = set(string.punctuation)\n",
    "    for text, category in zip([d[index] for d in data], labels):\n",
    "        r = ''.join([c if c not in punctuation else ' ' for c in text.lower()])\n",
    "        for word in r.split():\n",
    "            word_count[word] += 1\n",
    "            word_count_category[category][word] += 1\n",
    "\n",
    "    top_words = sorted([(word_count[word], word) for word in word_count], reverse=True)[:1000]\n",
    "    total = float(sum([w[0] for w in top_words]))\n",
    "    top_freq = [(w[0] / total, w[1]) for w in top_words]\n",
    "\n",
    "    top_words_category = defaultdict(list)\n",
    "    for count, word in top_words:\n",
    "        for category in word_count_category:\n",
    "            top_words_category[category].append((word_count_category[category][word], word))\n",
    "    total_category = {category:float(sum(zip(*top_words_category[category])[0])) for category in top_words_category}\n",
    "    top_freq_category = {category:[(count / total_category[category], word) for count, word in top_words_category[category]] for category in top_words_category}\n",
    "\n",
    "    more_freq = {category:sorted([(category_freq[0] - freq[0], freq[1]) for category_freq, freq in zip(top_freq_category[category], top_freq)], reverse=True)[:100] for category in top_freq_category}\n",
    "    return {category:set([pair[1] for pair in more_freq[category]]) for category in more_freq}\n",
    "\n",
    "text_keywords = get_keywords(train_data, train_labels, 1)\n",
    "summary_keywords = get_keywords(train_data, train_labels, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_category_counts = defaultdict(lambda: [0] * 5)\n",
    "for data, label in zip(train_data, train_labels):\n",
    "    user_category_counts[data[0]][label] += 1\n",
    "\n",
    "def user_keyword_counts(keywords, index):\n",
    "    counts = defaultdict(lambda: [0] * 5)\n",
    "    for data, label in zip(train_data, train_labels):\n",
    "        punctuation = set(string.punctuation)\n",
    "        r = ''.join([c if c not in punctuation else ' ' for c in data[index].lower()])\n",
    "        for word in r.split():\n",
    "            for category in keywords:\n",
    "                if word in keywords[category]:\n",
    "                    counts[data[0]][category] += 1\n",
    "    for user in counts:\n",
    "        total = float(sum(counts[user]))\n",
    "        for i in xrange(5):\n",
    "            counts[user][i] /= total\n",
    "    return counts\n",
    "\n",
    "user_review_keyword_counts = user_keyword_counts(text_keywords, 1)\n",
    "user_summary_keyword_counts = user_keyword_counts(summary_keywords, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy w/ lambda 0.01 = 0.81094\n"
     ]
    }
   ],
   "source": [
    "def feature(l, text_keywords, summary_keywords):\n",
    "    vector = []\n",
    "    vector.extend([sum([word in l[1] for word in text_keywords[category]]) for category in text_keywords])\n",
    "    vector.extend([sum([word in l[2] for word in summary_keywords[category]]) for category in summary_keywords])\n",
    "    vector.extend(([0] + user_category_counts[l[0]]) if l[0] in user_category_counts else [1, 0, 0, 0, 0, 0])\n",
    "    vector.extend(([0] + user_review_keyword_counts[l[0]]) if l[0] in user_review_keyword_counts else [1, 0, 0, 0, 0, 0])\n",
    "    vector.extend(([0] + user_summary_keyword_counts[l[0]]) if l[0] in user_summary_keyword_counts else [1, 0, 0, 0, 0, 0])\n",
    "    vector.append(l[3])\n",
    "    vector.append(l[4])\n",
    "    return vector\n",
    "\n",
    "train_features, valid_features = [], []\n",
    "\n",
    "for l in train_data:\n",
    "    train_features.append(feature(l, text_keywords, summary_keywords))\n",
    "\n",
    "for l in valid_data:\n",
    "    valid_features.append(feature(l, text_keywords, summary_keywords))\n",
    "\n",
    "best_lambda, best_accuracy = None, 0\n",
    "# for reg in [0.01, 0.1, 1, 10, 100]:\n",
    "for reg in [0.01]:\n",
    "    clf = svm.LinearSVC(C=reg)\n",
    "    clf.fit(train_features, train_labels)\n",
    "    scores = clf.decision_function(valid_features)\n",
    "    predict_valid = np.argmax(scores, axis=1)\n",
    "\n",
    "    accuracy = len(filter(lambda pair: pair[0] == pair[1], zip(predict_valid, valid_labels))) / float(len(predict_valid))\n",
    "    print \"Accuracy w/ lambda\", reg, \"=\", accuracy\n",
    "    if accuracy > best_accuracy:\n",
    "        best_lambda, best_accuracy = reg, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "review = []\n",
    "test_data = []\n",
    "for l in readGz(\"test_Category.json.gz\"):\n",
    "    review.append([l['reviewerID'], l['reviewHash']])\n",
    "    f = [l['reviewerID'], l['reviewText'], l['summary']]\n",
    "    f.extend([0, l['price']] if 'price' in l else [1, 0])\n",
    "    test_data.append(feature(f, text_keywords, summary_keywords))\n",
    "\n",
    "clf = svm.LinearSVC(C=best_lambda)\n",
    "clf.fit(train_features, train_labels)\n",
    "scores = clf.decision_function(test_data)\n",
    "predict_test = np.argmax(scores, axis=1)\n",
    "\n",
    "predictions = open(\"predictions_Category.txt\", 'w')\n",
    "predictions.write(\"userID-reviewHash,category\\n\")\n",
    "for key, value in zip(review, predict_test):\n",
    "    predictions.write(key[0] + '-' + key[1] + ',' + str(value) + '\\n')\n",
    "predictions.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
